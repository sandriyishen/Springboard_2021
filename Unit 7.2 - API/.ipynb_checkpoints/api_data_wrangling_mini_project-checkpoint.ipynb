{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "API_KEY = '' #removed key for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1. Collect data from the Frankfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Quandl API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "specifics = '&start_date=2017-01-01&end_date=2017-12-31&collapse=daily'\n",
    "url = 'https://www.quandl.com/api/v3/datasets/FSE/AFX_X/data.json?api_key=' + API_KEY + specifics\n",
    "r = requests.get(url)\n",
    "json = r.json()['dataset_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "print(json.keys())\n",
    "#for k in json.keys():\n",
    "#    print(k + ': ', json[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "column_names = json['column_names']\n",
    "dat = json['data']\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {k:[] for k in json['column_names']}\n",
    "for row in dat:\n",
    "    for i in range(len(data_dict.keys())):\n",
    "        data_dict[column_names[i]].append(row[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest opening price for Carl Zeiss Meditec was:  53.11\n",
      "Lowest opening price for Carl Zeiss Meditec was:  34.0\n"
     ]
    }
   ],
   "source": [
    "# isinstance was used to deal with missing values using base python, same list comprehension appears in following tasks as well\n",
    "print(\"Highest opening price for Carl Zeiss Meditec was: \", max([x for x in data_dict['Open'] if isinstance(x, float) == True]))\n",
    "print(\"Lowest opening price for Carl Zeiss Meditec was: \", min([x for x in data_dict['Open'] if isinstance(x, float) == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest price difference for Carl Zeiss Meditec within a single day was:  2.81\n"
     ]
    }
   ],
   "source": [
    "# zip was used to create tuples of High and Low price lists element-wise\n",
    "# isinstance was used to check if the difference is a number to deal with missing values\n",
    "# there is an assumption here that High is usually bigger than Low price\n",
    "diff = [h-l for h,l in zip(data_dict['High'], data_dict['Low']) if isinstance(h-l, float) == True]\n",
    "print(\"The largest price difference for Carl Zeiss Meditec within a single day was: \", round(max(diff), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between closing prices of Carl Zeiss Meditec occured between 2017-01-23 ( 34.06 ) and  2017-12-13 ( 53.09 ) \n",
      "for the total difference of: 19.03\n"
     ]
    }
   ],
   "source": [
    "# assuming that the task means any two days in 2017, we get the max and min closing prices in all of 2017 data that is not missing\n",
    "max_closing = max([x for x in data_dict['Close'] if isinstance(x, float) == True])\n",
    "min_closing = min([x for x in data_dict['Close'] if isinstance(x, float) == True])\n",
    "# we then find the index or location of max and min closing prices and in the print statement extract the corresponding dates using the indices\n",
    "max_index = data_dict['Close'].index(max_closing)\n",
    "min_index = data_dict['Close'].index(min_closing)\n",
    "print(\"The largest change between closing prices of Carl Zeiss Meditec occured between\", \n",
    "      data_dict['Date'][min_index], \"(\", data_dict['Close'][min_index], \") and \", data_dict['Date'][max_index], \"(\", data_dict['Close'][max_index], \n",
    "      \") \\nfor the total difference of:\", max_closing - min_closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between closing prices of Carl Zeiss Meditec from any two consecutive days occured on 2017-08-08 \n",
      "and the price of 44.37 on that date was changed from the previous date by 2.56\n"
     ]
    }
   ],
   "source": [
    "# now assuming that the task refers to consecutive two days' difference in closing price\n",
    "# we create an empty list and calculate consecutive difference using a for loop starting at index 1 position of closing price\n",
    "change_cumulative = []\n",
    "for i in range(1, len(data_dict['Close'])):\n",
    "    change = data_dict['Close'][i] - data_dict['Close'][i-1]\n",
    "    change_cumulative.append(change)\n",
    "# we then find max and min\n",
    "# note, it was possible to do this in a for loop, but since the data size was small, I did it after\n",
    "max_change = max([x for x in change_cumulative if isinstance(x, float) == True])\n",
    "min_change = min([x for x in change_cumulative if isinstance(x, float) == True])\n",
    "# max change can be positive or negative, so we compare the absolute values of max and min and assign it to max_val\n",
    "max_val = max_change if abs(max_change) > abs(min_change) else min_change\n",
    "# we then find the index of max_val and add 1 because we skipped first element of closing price before to use it later to find the associated data and closing price\n",
    "max_index = change_cumulative.index(max_val) + 1\n",
    "\n",
    "print(\"The largest change between closing prices of Carl Zeiss Meditec from any two consecutive days occured on\", data_dict['Date'][max_index], \n",
    "      \"\\nand the price of\", data_dict['Close'][max_index], \"on that date was changed from the previous date by\", round(max_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume for Carl Zeiss Meditec in 2017 was 89124.34\n"
     ]
    }
   ],
   "source": [
    "# using the same list comprehension as before, we remove missing values\n",
    "clean_volume = [x for x in data_dict['Traded Volume'] if isinstance(x, float) == True]\n",
    "# we then sum all elements in clean list and divide by number of elements to find the mean\n",
    "avg_traded = sum(clean_volume) / len(clean_volume)\n",
    "print(\"The average daily trading volume for Carl Zeiss Meditec in 2017 was\", round(avg_traded, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume for Carl Zeiss Meditec in 2017 was 76286.0\n"
     ]
    }
   ],
   "source": [
    "# we again clean the list to remove missing values\n",
    "clean_volume = [x for x in data_dict['Traded Volume'] if isinstance(x, float) == True]\n",
    "# we sort the list from smallest to largest\n",
    "clean_volume.sort()\n",
    "# print(clean_volume) if you want to verify it sorted correctly\n",
    "# we calculate the number of elements in the list\n",
    "n = len(clean_volume)\n",
    "# if the number is even, we find the average of two middle elements\n",
    "if n % 2 == 0:\n",
    "    median_traded = (clean_volume[n//2] + clean_volume[n//2-1])/2\n",
    "# else, we simply take the middle element as median\n",
    "else:\n",
    "    median_traded = clean_volume[n//2]\n",
    "    \n",
    "print(\"The median trading volume for Carl Zeiss Meditec in 2017 was\", round(median_traded, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
